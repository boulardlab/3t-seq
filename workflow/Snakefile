configfile: "config.yaml"


from pathlib import Path
from pprint import pprint as pp
from datetime import datetime
from urllib.parse import urlparse

# import json
import re
import pandas as pd

############
## HELPERS
############


def giga_to_byte(g):
    g = g - 2  # leave some memory to other processes
    return g * (1024**3)


def get_filename(link, decompress=False, stem=False):
    # sometimes we use this function to get filenames of paths instead of links.
    # convert back Path to str.
    if isinstance(link, Path):
        link = str(link)
    # parse
    p = urlparse(link)

    # cast to Path and get name attribute
    if stem:
        basename = Path(p.path).stem
    else:
        basename = Path(p.path).name

    # remove .gz
    if decompress and str(basename).endswith(".gz"):
        basename = basename.replace(".gz", "")

    return basename


def get_samples(wildcards, samples):
    if wildcards.serie in samples["single"]:
        s = samples["single"][wildcards.serie]
    else:
        s = samples["paired"][wildcards.serie]
    return s


#######################
## DEFINE VARIABLES
#######################


date = datetime.now()
timestamp = date.strftime("%Y-%m-%d")

log_folder = Path(config["globals"]["log_folder"])
log_folder = log_folder.joinpath(timestamp)

data_folder = Path(config["globals"]["results_folder"])
qc_folder = Path(config["globals"]["qc_folder"])
reads_folder = Path(config["globals"]["reads_folder"])
references_folder = Path(config["globals"]["references_folder"])
tmp_folder = Path(config["globals"]["tmp_folder"])
analysis_folder = Path(config["globals"]["analysis_folder"])

raw_reads_folder = reads_folder
trim_reads_folder = data_folder.joinpath("trim")
rdata_folder = analysis_folder.joinpath("rdata")
pictures_folder = analysis_folder.joinpath("pictures")
tables_folder = analysis_folder.joinpath("tables")
notebooks_folder = analysis_folder.joinpath("notebooks")

fastqc_raw_folder = qc_folder.joinpath("fastqc-raw")
fastqc_trim_folder = qc_folder.joinpath("fastqc-trimmed")
fastqc_markdup_folder = qc_folder.joinpath("fastqc-markdup")
fastqc_star_folder = qc_folder.joinpath("star")

multiqc_folder = qc_folder.joinpath("multiqc")
multiqc_raw_folder = multiqc_folder.joinpath("raw")
multiqc_trim_folder = multiqc_folder.joinpath("trim")
multiqc_star_folder = multiqc_folder.joinpath("star")
multiqc_markdup_folder = multiqc_folder.joinpath("markdup")

alignments_folder = data_folder.joinpath("alignments")
star_folder = alignments_folder.joinpath("star")
markdup_folder = alignments_folder.joinpath("star_markdup")
starTE_folder = alignments_folder.joinpath("starTE")
salmonTE_folder = data_folder.joinpath("salmonTE")

trna_coverage_folder = data_folder.joinpath("tRNA_coverage")

# featureCount_folder = starTE_folder.joinpath("featureCount")

deseq2_working_directory = Path(config["deseq2"]["working_directory"])
deseq2_notebook_input_path = Path(config["deseq2"]["notebook_path"])


# disable_trim = config["trim"]["disable"]

## These folders will be create at the beginning of the pipeline
init_folders = [
    log_folder,
    reads_folder,
    raw_reads_folder,
    trim_reads_folder,
    multiqc_folder,
    alignments_folder,
    references_folder,
    tmp_folder,
    star_folder,
    starTE_folder,
    salmonTE_folder,
    # featureCount_folder,
    tables_folder,
    pictures_folder,
    notebooks_folder,
]

## Generate paths for sequence data from links
fasta_path = references_folder.joinpath(
    get_filename(config["genome"]["fasta_link"], decompress=True)
)

if "gtf_link" in config["genome"].keys():
    gtf_path = references_folder.joinpath(
        get_filename(config["genome"]["gtf_link"], decompress=True)
    )
    disable_gtf_download = False
elif "gtf_path" in config["genome"].keys():
    gtf_path = references_folder.joinpath(
        get_filename(config["genome"]["gtf_path"], decompress=True)
    )
    disable_gtf_download = True
else:
    raise ValueError("Invalid config: specify either gtf_link or gtf_path")

if "rmsk_link" in config["genome"]:
    rmsk_path = references_folder.joinpath(
        get_filename(config["genome"]["rmsk_link"], decompress=False)
    )
elif "rmsk_path" in config["genome"]:
    rmsk_path = Path(config["genome"]["rmsk_path"])
    config["genome"]["rmsk_link"] = None
else:
    raise ValueError("Invalid config: specify either rmsk_link or rmsk_path")
rmsk_bed = Path(str(rmsk_path).replace("gtf", "bed"))
gaf_path = references_folder.joinpath(
    get_filename(config["genome"]["gaf_link"], decompress=False)
)
tRNA_annotation_file = config["genome"]["gtrnadb_bed"]

## Get samples
libraries = config["sequencing_libraries"]
samples = {"single": {}, "paired": {}}
for library in libraries:
    libname = library["name"]
    # libtype = library["type"]
    # if libtype == 'GeneCore':
    #     index_path = library["index"]
    #
    #     # extract filelist from json file
    #     index = json.load(open(index_path))
    #     filelist = index["data"][0]["lanes"][0]["filelist"]
    #     filelist = pd.DataFrame(filelist)
    #
    #     seqtype = index["data"][0]["lanes"][0]["type"]
    #
    #     # get "name" column. Contains entire filenames (with extensions)
    #     filelist = filelist["name"].tolist()
    #     filelist = [ filename.split(".")[0] for filename in filelist ]
    #
    #     if seqtype == 'paired-end':
    #         samples['paired'][libname] = [ x.replace('_1_sequence', '') for x in filelist if x.endswith('_1_sequence')]
    #
    #     else:
    #         samples['single'][libname] = filelist
    #
    # elif libtype == "SRA":

    sample_sheet = pd.read_csv(library["sample_sheet"])
    protocol = "pe" if "filename_2" in sample_sheet.columns else "se"

    if protocol == "pe":
        filelist = sample_sheet.filename_1.tolist()
        samples["paired"][libname] = [
            re.sub(r"_1(?:_sequence)?", "", x) for x in filelist
        ]
    else:
        filelist = sample_sheet.filename.tolist()
        samples["single"][libname] = filelist

    if any([re.match(".*.f(?:ast)?q(?:.gz)?$", x) for x in filelist]):
        raise NameError(
            "Filenames should not contain extensions. Remove .fastq.gz or .fq.gz from the filename column(s)."
        )

pp(samples)

library_names_single = list(samples["single"].keys())
library_names_paired = list(samples["paired"].keys())

####################
## ONSTART BLOCK
####################


def mkdir(p: Path, verbose=False):
    if not p.exists():
        p.mkdir(parents=True, exist_ok=True)
        if verbose:
            print("Created {}".format(p))


onstart:
    for folder in init_folders:
        mkdir(folder)


############
## HELPERS
############


def get_bw(wildcards):
    """Builds bigwig paths for rule all"""
    o = []
    for lib in library_names_single + library_names_paired:
        if lib in samples["single"].keys():
            s = samples["single"][lib]
        else:
            s = samples["paired"][lib]
        o += expand(star_folder.joinpath("{serie}", "{sample}.bw"), serie=lib, sample=s)
    return o


def get_star_input(wildcards):
    """Builds input paths for STAR alignment testing if a library is single-end or paired-end"""
    supported_extensions = ["fq", "fq.gz", "fastq", "fastq.gz"]
    if wildcards.serie in library_names_single:
        for ext in supported_extensions:
            infile = trim_reads_folder.joinpath(
                wildcards.serie, 
                f"{wildcards.sample}.{ext}")
            if os.path.exists(infile):
                break
    else:
        for ext in supported_extensions:
            infile = [
                trim_reads_folder.joinpath(
                    wildcards.serie, 
                    f"{wildcards.sample}_1.{ext}"
                    ),
                trim_reads_folder.joinpath(
                    wildcards.serie, 
                    f"{wildcards.sample}_2.{ext}"
                    ),
            ]
            if all([os.path.exists(f) for f in infile]):
                break
    return infile


def get_params(wildcards, key):
    """Returns the value of a specific key for the current serie"""
    params = ""
    for lib in config["sequencing_libraries"]:
        if lib["name"] == wildcards.serie:
            params = lib[key]
    return params


def get_sample_sheet(wildcards):
    """Returns path to sample sheet for current serie"""
    return get_params(wildcards, "sample_sheet")


def get_fastq(wildcards):
    supported_extensions = ["fq", "fq.gz", "fastq", "fastq.gz"]
    for ext in supported_extensions:
        candidate = raw_reads_folder.joinpath(wildcards.serie, f"{wildcards.sample}.{ext}")
        if os.path.exists(candidate):
            return candidate
    raise ValueError(f"Could not find FastQ file. Check your naming. Supported extensions: {supported_extensions}") 

def get_fastq_paired(wildcards):
    supported_extensions = ["fq", "fq.gz", "fastq", "fastq.gz"]
    supported_suffixes = [
        ("_1", "_2"),
        ("_R1", "_R2"),
        ("_1_sequence", "_2_sequence"),
    ]
    for ext in supported_extensions:
        for suffix in supported_suffixes:
            candidate1 = raw_reads_folder.joinpath(wildcards.serie, f"{wildcards.sample}{suffix[0]}.{ext}")
            candidate2 = raw_reads_folder.joinpath(wildcards.serie, f"{wildcards.sample}{suffix[1]}.{ext}")
            if os.path.exists(candidate1) and os.path.exists(candidate2):
                return {"m1": candidate1, "m2": candidate2}
    raise ValueError(f"Could not find FastQ files. Check your naming.\nPaired-end suffixed: {supported_suffixes}.\nSupported extensions: {supported_extensions}") 
    

############
## RULES
############


wildcard_constraints:
    se_serie="|".join(library_names_single),
    pe_serie="|".join(library_names_paired),
    method="multihit|random",


# include: "../include/download_sra.smk"
include: "include/fastqc.smk"
include: "include/trim_single.smk"
include: "include/download_genome_fasta_file.smk"


if not disable_gtf_download:

    include: "include/download_genome_annotation_file.smk"


include: "include/star_genome_preparation.smk"
include: "include/star_single.smk"
include: "include/deseq2.smk"
include: "include/salmonTE_quant.smk"
include: "include/salmonTE_test.smk"
include: "include/edit_condition_file.smk"
include: "include/starTE_align_random.smk"
include: "include/starTE_align_multihit.smk"
include: "include/download_repeatmasker_annotation_file.smk"
include: "include/featureCounts_random.smk"
include: "include/featureCounts_multihit.smk"
include: "include/deseq2_report.smk"
include: "include/deseq2_subset_gtf.smk"
include: "include/filter_bam.smk"
include: "include/gtf2bed.smk"
include: "include/picard_markdup.smk"
include: "include/download_gaf_file.smk"
include: "include/make_bw.smk"
include: "include/coverage_tRNA.smk"


rule all:
    input:
        # MultiQC reports at different steps
        expand(
            multiqc_raw_folder.joinpath("{serie}", "multiqc_report.html"),
            serie=library_names_single + library_names_paired,
        ),
        expand(
            multiqc_trim_folder.joinpath("{serie}", "multiqc_report.html"),
            serie=library_names_single + library_names_paired,
        ),
        expand(
            multiqc_star_folder.joinpath("{serie}", "multiqc_report.html"),
            serie=library_names_single + library_names_paired,
        ),
        expand(
            multiqc_markdup_folder.joinpath("{serie}", "multiqc_report.html"),
            serie=library_names_single + library_names_paired,
        ),
        # DESeq2 flags
        expand(
            analysis_folder.joinpath("deseq2-{serie}.done"),
            serie=library_names_single + library_names_paired,
        ),
        # SalmonTE results folders
        expand(
            data_folder.joinpath("salmonTE/de_analysis/{se_serie}"),
            se_serie=library_names_single,
        ),
        expand(
            data_folder.joinpath("salmonTE/de_analysis/{pe_serie}"),
            pe_serie=library_names_paired,
        ),
        # FeatureCounts tables from STAR-TE
        expand(
            starTE_folder.joinpath("{se_serie}/featureCount/{method}.txt"),
            se_serie=library_names_single,
            method=["multihit", "random"],
        ),
        expand(
            starTE_folder.joinpath("{pe_serie}/featureCount/{method}.txt"),
            pe_serie=library_names_paired,
            method=["multihit", "random"],
        ),
        # Bigwig files
        get_bw,
        # tRNA coverage files
        expand(
            trna_coverage_folder.joinpath("{serie}", "tRNA_matrix.txt"),
            serie=library_names_paired + library_names_single,
        ),
        # expand(multiqc_folder.joinpath("{se_serie}", "multiqc_report.html"), se_serie=library_names_single),
        # expand(rdata_folder.joinpath("deseq2/{se_serie}/dds.rds"), se_serie=library_names),
        # expand(tables_folder.joinpath("deseq2/{se_serie}/results.csv"), se_serie=library_names),
        # expand(notebooks_folder.joinpath("{se_serie}/%s.html"%get_filename(deseq2_notebook_input_path, stem=True)), se_serie=library_names_single),
        # expand(multiqc_folder.joinpath("{pe_serie}", "multiqc_report.html"), pe_serie=library_names_paired),
        # expand(rdata_folder.joinpath("deseq2/{pe_serie}/dds.rds"), pe_serie=library_names),
        # expand(tables_folder.joinpath("deseq2/{pe_serie}/results.csv"), pe_serie=library_names),
        # expand(notebooks_folder.joinpath("{pe_serie}/%s.html"%get_filename(deseq2_notebook_input_path, stem=True)), pe_serie=library_names_paired),
        # expand(rdata_folder.joinpath("deseq2/{serie}/dds.rds"), serie = library_names_single + library_names_paired)
        # expand(analysis_folder.joinpath("deseq2-report-{serie}.done"), serie = library_names_single + library_names_paired),
